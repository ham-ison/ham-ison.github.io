[{"title":"[object Object]","path":"/2025/03/22/2022-03-29-Rendering-a-Scene-with-Deferred-Lighting/","content":"Tile-based模式的GPU光照的计算是非常消耗计算资源的，为了减少光照的重复计算，通过实施延时光照渲染来进行优化。 概述通过Apple例子来看一下延时光照渲染实施方法，这个例子应用shadow map（阴影贴图）实现阴影，并使用模版缓冲区剔除光量。 与 Forward lighting相比，Deferred lighting可以渲染大量的灯光数量。比如，在Forward lighting模式下，如果场景中有很多光源，无法对每个光源在每个片元上作用的计算量进行全量计算。需要应用到复杂的排序和像素合并算法来筛除对每个片元能产生作用的光源来限制计算量。使用Deferred lighting，可以容易地将多个光源应用到场景中。 重要概念在开始解读示例代码的之前，回顾一下以下概念可以更好的理解关键细节。 传统延时光照渲染传统延时光照渲染通常分为两个渲染通道： 第一个渲染通道：G-buffer 渲染。渲染器绘制和变换场景里的模型，片元函数将渲染结果输出到 “几何缓冲区” 和 “G-Buffer”中。G-Buffer包含了模型的材料颜色信息，以及每个片元的法线、阴影和深度信息。 第二个渲染通道：延时光照和构图。渲染器绘制每个光柱，使用G-Buffer中的数据重建每个片元的位置信息并应用光照计算。绘制光源时，该光源输出为混合前一个光源的输出后的结果。最后，渲染器将其他数据（如阴影和定向光照）合成到场景中。 一些macOS的GPU是”即时渲染”（IMR）架构。IMR GPU延时光照只能通过两个渲染通道实现。所以这个例子的macOS版本实现了两个通道的延时光照算法。 Apple芯片GPU上的单通道延时光照Apple芯片GPU使用了基于磁贴分片的延迟渲染（TBDR）架构，TBDR架构在GPU内部专门为第一块磁贴设计了内存来存储渲染数据。渲染结果存储到磁贴内存中，可以避免数据在GPU和系统内存中所花费的大量资源消耗，GPU和系统内存DDR是通过带宽受限的内存总线交换数据。GPU什么时候需要将磁贴内存写入到系统内存取决于以下配置情况： 应用程序主动执行了存储命令 应用程序纹理的存储模式将 “MTLStoreAction.store”设置为存储操作时，渲染通道中的渲染目标的输出数据将从磁贴内存中写入系统内存。如果这些数据将用于后续的渲染通道，这些纹理将做为输入数据从系统内存中读入到GPU的纹理缓存中。因此，传统的延时光照渲染器要求第一次和第二次渲染通道之间将G-Buffer数据存储在系统内存中。 由于TBDR架构允许在任何时间从磁贴内存中读取数据。这允许片元着色器从磁贴内存中读取数据并对渲染目标进行计算，然后将数据再次写入磁贴内存。这个特性避免了在第一次和第二次渲染通道之间将G-Buffer数据存储到系统内存中。所以，TBDR架构下延迟光照渲染器可以通过单个渲染通道实现。G- Buffer在单个渲染通道由GPU（而不是CPU）生成和使用。因此，在渲染通道开始之前，不会从系统内存中加载数据，也不会在渲染通道完成后将结果存储在系统内存中。光照片元函数不是从系统内存中的纹理读取G-Buffer数据，而是从G-Buffer读取数据，同时它仍然作为渲染目标附加到渲染通道。因此，不需要为G-Buffer纹理分配系统内存，可以使用MTLStorageMode.memoryless存储模式声明这些纹理。 允许TBDR GPU从片元函数中附加的渲染目标读取数据的特性称为”可编程混合” 具有栅格顺序组的延时光照默认情况下，当片元着色器将数据写入像素时，GPU会等到着色程序完全完成对该像素的写入后，再开始为同一个像素执行另一个片元着色程序。 栅格顺序组允许应用程序增加GPU片元着色器的并行化。使用栅格顺序组，片元函数可以将渲染目标分隔到不同的执行组中。这种分离执行允许GPU在片元着色器的上一个实例完成时将数据写入另一个组的像素之前，读取一个组中的渲染目标并对其执行计算。 在示例程序中，一些光照片元函数使用了栅格顺序组： Raster order group 0. “AAPLLightingROG” 用于包含光照计算结果的渲染目标 Raster order group 1. “AAPLGBufferROG” 用于光照函数中G-Buffer数据。 这些栅格顺序组允许GPU在上一个片元着色器完成光照计算并写入输出数据之前读取片元着色器中的G-Buffer并执行光照计算。 渲染延时光照帧这个示例通过以下阶段来显示完整帧： 阴影贴图 G-Buffer 定向光 光蒙板 点光源 天空盒 彩色小灯 示例的单通道延时渲染器生成G-Buffer并在单个渲染通道中执行所有后续阶段。由于IOS和tvOS的GPU是TBDR架构，单通道实现允许设备从磁贴内存中的渲染目标读取G-Buffer数据。 1234567891011encodePass(into: commandBuffer, using: gBufferAndLightingPassDescriptor, label: &quot;GBuffer &amp; Lighting Pass&quot;) &#123; renderEncoder in encodeGBufferStage(using: renderEncoder) encodeDirectionalLightingStage(using: renderEncoder) encodeLightMaskStage(using: renderEncoder) encodePointLightStage(using: renderEncoder) encodeSkyboxStage(using: renderEncoder) encodeFairyBillboardStage(using: renderEncoder)&#125; 示例程序的传统延时渲染在一个渲染通道中生成G-Buffer，然后在另一个渲染通道中执行后续 123456encodePass(into: commandBuffer, using: gBufferPassDescriptor, label: &quot;GBuffer Generation Pass&quot;) &#123; renderEncoder in encodeGBufferStage(using: renderEncoder)&#125; 12345678910encodePass(into: commandBuffer, using: lightingPassDescriptor, label: &quot;Lighting Pass&quot;) &#123; (renderEncoder) in encodeDirectionalLightingStage(using: renderEncoder) encodeLightMaskStage(using: renderEncoder) encodePointLightStage(using: renderEncoder) encodeSkyboxStage(using: renderEncoder) encodeFairyBillboardStage(using: renderEncoder)&#125; 渲染阴影贴图示例程序通过从光源的透视渲染模型，为场景中的单个定向光源（太阳）渲染阴影贴图。 阴影贴图的渲染管线有顶点函数，但是没有片元函数。因此，这个示例程序无需执行渲染管线的后续阶段就可确定写入阴影贴图的屏幕空间深度值。渲染器执行由于没有片元函数，因此执行很快。 1234lazy var shadowGeneration = makeRenderPipelineState(label: &quot;Shadow Generation Stage&quot;) &#123; descriptor in descriptor.vertexFunction = library.makeFunction(name: &quot;shadow_vertex&quot;) descriptor.depthAttachmentPixelFormat = .depth32Float&#125; 在为阴影贴图绘制几何图形之前，该示例程序设置了深度偏差值以减少阴影伪影： 1renderEncoder.setDepthBias(0.015, slopeScale: 7, clamp: 0.02) 然后，在片元函数的G-Buffer阶段，示例程序判断片元是否被遮挡或被阴影遮罩。 123// Compare the depth value in the shadow map to the depth value of the fragment in the sun&#x27;s.// frame of reference. If the sample is occluded, it will be zero.float shadow_sample = shadowMap.sample_compare(shadowSampler, in.shadow_coord.xy, in.shadow_coord.z); 示例程序将sample_compare函数的结果存储在 normal_shadow的渲染目标的”W”组件中 1gBuffer.normal_shadow = half4(eye_normal.xyz, shadow_sample); 在定向光和点光源合成阶段，示例程序从G-Buffer中读取阴影值并应用到片元上。 渲染G-Buffer示例程序包含以下纹理： albedoSpecular：存储反射率和镜面反射数据，反射数据存储在”x”, “y”,和”z”分量中，镜面反射数据存储在”w”分量中。 normalShadow：存储法线和阴影数据。法线数据存储在 “x”, “y”和”z”分量中，阴影数据存储在”w”分量中。 depth：存储视野空间的深度信息值。 示例程序渲染G-Buffer，传统渲染器和单通道延时渲染器都将所有G-Buffer纹理做为渲染通道的渲染目标。然而，由于使用TBDR架构的设备即可以渲染G-Buffer，也可以在单渲染通道中读取G-Buffer。因此这个示例程序将创建具有无内存存储模式的G-Buffer纹理，这表示不会为这些纹理分配系统内存。相反，这些纹理仅在渲染通道期间在磁贴内存中分配和填充。 示例程序根据”drawableSizeWillChange”属性来决定如何创建G-Buffer纹理。单通道延迟渲染将”storageMode”变量设置为”MTLStorageMode.memoryless”,而传统的延迟渲染将其设置为MTLStroageMode.private. 1var storageMode = MTLStorageMode.private 对于传统的延迟渲染，在示例程序完成了G-Buffer纹理的写数据后，它会调用”endEncoding”方法来完成G-Buffer渲染通道。由于渲染命令编码器的存储操作设置为”MTLStoreAction.store”,因此GPU会在编码器完成执行后将每个渲染目标纹理写入”Video”内存。这允许示例程序在随后的延迟光照和构图渲染通道中从”Video”内存中读取这些数据。 对于单通道延迟渲染器，在示例程序完成G-Buffer纹理写入数据后，示例程序不会完成渲染命令编码器，而是继续将其用于后续阶段。 应用定向光照和阴影该示例程序将定向光照和阴影应用于要显示的可绘制对象。 传统的延迟渲染器从设置为片元函数的参数的纹理中读取G-Buffer数据： 1234567fragment half4deferred_directional_lighting_fragment_traditional( QuadInOut in [[ stage_in ]], constant AAPLFrameData &amp; frameData [[ buffer(AAPLBufferFrameData) ]], texture2d&lt;half&gt; albedo_specular_GBuffer [[ texture(AAPLRenderTargetAlbedo) ]], texture2d&lt;half&gt; normal_shadow_GBuffer [[ texture(AAPLRenderTargetNormal) ]], texture2d&lt;float&gt; depth_GBuffer [[ texture(AAPLRenderTargetDepth) ]]) 单通道延迟渲染器从附加到渲染通道的渲染目标中读取G-Buffer数据： 1234567struct GBufferData&#123; half4 lighting [[color(AAPLRenderTargetLighting), raster_order_group(AAPLLightingROG)]]; half4 albedo_specular [[color(AAPLRenderTargetAlbedo), raster_order_group(AAPLGBufferROG)]]; half4 normal_shadow [[color(AAPLRenderTargetNormal), raster_order_group(AAPLGBufferROG)]]; float depth [[color(AAPLRenderTargetDepth), raster_order_group(AAPLGBufferROG)]];&#125;; 1234deferred_directional_lighting_fragment_single_pass( QuadInOut in [[ stage_in ]], constant AAPLFrameData &amp; frameData [[ buffer(AAPLBufferFrameData) ]], GBufferData GBuffer) 尽管这些片元函数有不同的输入，但是它们在”deferred_directional_lighting_fragment_common”片元函数中共享一个共同的实现。这个函数执行以下操作： 从G-Buffer法线数据重建法线以计算漫反射项。 根据G-Buffer深度数据重建视野空间位置，并应用镜面反射高光。 使用G-Buffer阴影数据使片元变暗，并将阴影应用于场景。 由于这是渲染到可绘制对象的第一个阶段，因此iOS和tvOS渲染器会在较早的G-Buffer阶段之前获取可绘制对象，这样可绘制对象可以与后续阶段的输出合并。然而，传统的延迟渲染器会延迟获取可绘制对象，一直到G-Buffer阶段完成之后和开始计算定向光之前。这种延迟减少了应用程序在绘制对象上花费的时间，从而提高了性能。 由于”DepthStencilStates”对象的”directionalLighting”属性的状态，”deferred_directional_lighting_fragment”函数仅对应点亮的片元执行。这种优化简单而重要，可以节省许多片元着色器执行的周期。 剔除光源体积这个示例程序创建一个模版蒙板，用来避免对许多片元执行昂贵的光照计算。它通过使用G-Buffer通道中的深度缓冲区和模版缓冲区来创建此模版蒙板，以跟踪光体积与其他几何体相交。（如果没有相交，那么它就不会照亮任何东西） 在”encodeLightMaskStage”实现中，本示例程序设置”PipelineStates”类的”lightMask”对象，并对实例化的绘制调用进行编码，用来绘制二十面体的背面，这些二十面体包含点光源的体积。如果此绘制调用中片元未通过深度测试，则此结果指示二十面体的背面位于某些几何图形后面。 12345678910111213141516171819202122232425renderEncoder.setRenderPipelineState(lightMaskPipelineState)renderEncoder.setDepthStencilState(lightMaskDepthStencilState)renderEncoder.setStencilReferenceValue(128)renderEncoder.setCullMode(.front)renderEncoder.setVertexBuffer(scene.frameData, offset: 0, index: Int(AAPLBufferFrameData.rawValue))renderEncoder.setVertexBuffer(scene.pointLights, offset: 0, index: Int(AAPLBufferIndexLightsData.rawValue))renderEncoder.setVertexBuffer(scene.lightPositions, offset: 0, index: Int(AAPLBufferIndexLightsPosition.rawValue))renderEncoder.setFragmentBuffer(scene.frameData, offset: 0, index: Int(AAPLBufferFrameData.rawValue))renderEncoder.draw(meshes: [scene.icosahedron], instanceCount: scene.numberOfLights, requiresMaterials: false) “lightMask”管线对象没有片元函数，因此不会从此渲染管线写入任何颜色数据。但是，由于设置了”lightMask”深度和模版状态，任何未通过深度测试的片元都会增加片元的模版缓冲区。包含几何图形的片元的起始深度值为”128”，示例程序在G-Buffer阶段设置了这个值。因此，任何未通过深度测试的片元都将会深度值递增为大于”128”。（由于使能了正面剔除，因此未通过深度测试且值大于”128”的片元表示至少二十面体的后半部分位于所有几何图形的后面。） 在下一个绘制调用中， 在”encodePointLightStage”实现中，该示例程序将点光源的贡献应用于可绘制对象。该示例程序测试二十面体的前半部分是否在所有几何体的前面，这决定了光体积是否与某些几何体相交，从而确实片元是否应该被点亮。仅当片元的模版值大于”128”的引用值时，为此绘制调用设置的深度和模版状态”pointLight”仅执行片元函数。（由于模版测试值设置为”MTLCompareFunction.less”,因此仅当参考值”128”小于模版缓冲区中的值时，示例程序才会通过测试。 12345678910111213141516171819202122232425renderEncoder.setRenderPipelineState(lightMaskPipelineState)renderEncoder.setDepthStencilState(lightMaskDepthStencilState)renderEncoder.setStencilReferenceValue(128)renderEncoder.setCullMode(.front)renderEncoder.setVertexBuffer(scene.frameData, offset: 0, index: Int(AAPLBufferFrameData.rawValue))renderEncoder.setVertexBuffer(scene.pointLights, offset: 0, index: Int(AAPLBufferIndexLightsData.rawValue))renderEncoder.setVertexBuffer(scene.lightPositions, offset: 0, index: Int(AAPLBufferIndexLightsPosition.rawValue))renderEncoder.setFragmentBuffer(scene.frameData, offset: 0, index: Int(AAPLBufferFrameData.rawValue))renderEncoder.draw(meshes: [scene.icosahedron], instanceCount: scene.numberOfLights, requiresMaterials: false) 由于”encodeLightMaskStage”中的绘制调用会增加任何几何图形后面的片元的模版值，因此示例程序对其执行片元函数的唯一片元是满足以下两个条件的片元： 正面通过深度测试且位于某些几何形状前面的片元 背面未通过深度测试且位于某些几何形状后面的片元 下面显示了使用此模版蒙板算法的渲染帧与不使用此模版蒙板算法的渲染帧在片元覆盖率方面的差异。算法使能后，绿色像素是为其执行点光源片元函数的像素。 禁用算法时，绿色和红色的像素是其执行点光源片元函数的像素。 渲染天空盒和彩色光源在最终的光照阶段，示例程序将更简单的光照技术应用到场景中。 示例程序对模型的几何体在天空盒的深度测试，渲染器仅渲染可以被几何体填充的部分。 12345678910renderEncoder.setRenderPipelineState(pipelineStates.skybox)renderEncoder.setDepthStencilState(depthStencilStates.skybox)renderEncoder.setCullMode(.front)renderEncoder.setVertexBuffer(scene.frameData, offset: 0, index: Int(AAPLBufferFrameData.rawValue))renderEncoder.setFragmentTexture(scene.skyMap, index: Int(AAPLTextureIndexBaseColor.rawValue))renderEncoder.draw(meshes: [scene.skyMesh], requiresMaterials: false) 示例程序将彩色光源渲染到可绘制的2D圆形区域，并使用纹理来确定其片元的透明混合因子。 12345half4 c = colorMap.sample(linearSampler, float2(in.tex_coord));half3 fragColor = in.color * c.x;return half4(fragColor, c.x);","tags":["Metal","图形学"],"categories":["设计开发","图形学"]},{"title":"使用Trae AI来创建ison7工程","path":"/2025/03/21/2025-03-16-使用Trae AI来创建ison7工程/","content":"2025年3月16日 使用Trae AI来创建ison7工程先通过一段描述我想要开发的功能文字描述给Trae，要求Trae帮我选型，然后将选型的架构做了一些定制化，完成一个设想的架构雏形，将架构中的内容给到Trae AI，生成目录的基本结构，完善技术栈选型：前端使用React Flow+Canvas实现节点交互，后端采用Node.js主服务+Python辅助AI模块，数据库组合PostgreSQL存储结构化数据+MongoDB存文档。建议优先建立项目基础框架，补充缺失的代码目录如src&#x2F;features协作模块、src&#x2F;api接口层，并完善Electron集成配置。创建了项目基础目录结构，包括前端功能模块、API接口层以及Electron主进程配置，为后续功能开发打下基础。执行以下命令后，启动项目，暂时还无法显示内容，生成的程序还需要进行调整。 1npm run start 让DeepSeek给我写一下ison7的架构设计方案12345最简单的提示词工程：# 角色：你是一个软件设计专家# 任务：请帮我修改一下以下内容的描述，让文字更专业更有逻辑性# 内容：先通过一段描述我想要开发的功能文字描述给Trae，要求Trae帮我选型，然后将选型的架构做了一些定制化，完成一个设想的架构雏形，将架构中的内容给到Trae AI，生成目录的基本结构，完善技术栈选型：前端使用React Flow+Canvas实现节点交互，后端采用Node.js主服务+Python辅助AI模块，数据库组合PostgreSQL存储结构化数据+MongoDB存文档。建议优先建立项目基础框架，补充缺失的代码目录如src/features协作模块、src/api接口层，并完善Electron集成配置。创建了项目基础目录结构，包括前端功能模块、API接口层以及Electron主进程配置，为后续功能开发打下基础。执行以下命令后，启动项目，暂时还无法显示内容，生成的程序还需要进行调整。 以下是针对您需求的优化重构方案，采用专业软件架构文档格式呈现： 智能节点编排系统架构设计方案一、系统架构设计方法论 需求驱动选型原则 基于可视化编排的核心需求，采用React Flow+Canvas双引擎架构 遵循”前端轻量化，后端服务化”的设计理念，实现关注点分离 采用混合持久化策略应对不同数据形态需求 技术选型决策树 123456789graph TD A[功能需求] --&gt; B&#123;是否需要实时协作?&#125; B --&gt;|是| C[CRDT+WebSocket] B --&gt;|否| D[RESTful API] C --&gt; E[Yjs/Turbo协议选型] D --&gt; F[Express/Nest.js] A --&gt; G&#123;是否需要AI集成?&#125; G --&gt;|是| H[Python微服务] G --&gt;|否| I[纯Node.js] 二、技术架构蓝图2.1 分层架构设计 层级 技术组件 功能说明 展示层 React Flow Pro + Konva.js 实现可视化节点编排与高阶交互 业务逻辑层 Redux Toolkit + Zustand 状态管理与业务规则处理 服务层 Node.js主服务 + Python AI微服务 核心业务处理与智能增强 数据层 PostgreSQL + MongoDB 结构化数据与文档型数据分离存储 基础设施层 Docker + Kubernetes 容器化部署与资源调度 2.2 关键模块设计前端工程化方案 123456789101112src/├── features/ # 功能模块│ ├── workflow/ # 节点编排核心逻辑│ ├── collaboration # 实时协作实现│ └── ai/ # AI交互模块├── api/ # 接口层│ ├── rest/ # RESTful适配器│ └── websocket/ # WS协议处理├── electron/ # 桌面端集成│ ├── main.js # 主进程配置│ └── preload.js # 进程通信桥接└── shared/ # 通用组件库 Electron集成方案 123456789101112131415161718// vite.config.jsexport default defineConfig(&#123; plugins: [ electron(&#123; main: &#123; entry: &#x27;electron/main.js&#x27;, vite: &#123; build: &#123; outDir: &#x27;dist/electron&#x27; &#125; &#125; &#125;, preload: &#123; input: &#x27;electron/preload.js&#x27; &#125; &#125;) ]&#125;) 三、实施路线图3.1 基础框架搭建阶段 工程初始化 123npm create vite@latest --template react-tsnpm install @electron-forge/cli -gelectron-forge init src/electron --template=vite 核心依赖安装 1npm install reactflow konva react-konva yjs @yjs/provider-websocket 3.2 开发环境配置要点 跨域解决方案 1234567// server/middleware/cors.jsapp.use(cors(&#123; origin: process.env.ELECTRON_MODE ? &#x27;file://&#x27; : [&#x27;http://localhost:3000&#x27;], methods: [&#x27;GET&#x27;,&#x27;POST&#x27;,&#x27;PUT&#x27;,&#x27;DELETE&#x27;]&#125;)) 构建优化配置 123456// electron/main.jsif (process.env.NODE_ENV === &#x27;development&#x27;) &#123; win.loadURL(&#x27;http://localhost:3000&#x27;)&#125; else &#123; win.loadFile(path.join(__dirname, &#x27;../dist/index.html&#x27;))&#125; 四、问题诊断与解决方案当前启动异常排查指南 依赖完整性检查 1npm ci --force # 强制清理缓存安装 进程冲突检测 1lsof -i :3000 # 检查端口占用 构建产物验证 1npx electron-builder --dir --config # 检查打包配置 五、后续开发建议 架构增强方向 引入SWC编译器优化构建速度 配置Module Federation实现动态加载 集成Sentry进行错误监控 质量保障措施 123456graph LR A[单元测试] --&gt; B(Jest+Testing-Library) C[E2E测试] --&gt; D(Cypress) E[集成测试] --&gt; F(Supertest) G[性能测试] --&gt; H(Lighthouse) I[安全测试] --&gt; J(Snyk) 本方案通过模块化设计、分层架构和工程化配置，建立了可扩展的开发基础。建议后续采用Monorepo结构管理多平台代码，逐步实现从MVP到生产环境的演进。 以下是早期用于设想的架构设计方案： ison7 软件架构选型1. 软件架构设计架构模式 前后端分离（前端和后端通过 API 交互，提升扩展性） 微服务架构（拆分不同服务，如存储、协作、AI 辅助） Serverless（低成本、弹性扩展需求） 2. 技术栈选型前端选型方案 框架：Vite + React + TypeScript + Canvas 组件化开发，生态丰富，适合复杂交互 TypeScript 提高代码可维护性 Vite + React + Canvas（轻量、可定制） 待定：react-flow（轻量、可定制、支持拖拽） UI 组件库 Tailwind CSS（轻量、可自定义） Shadcn&#x2F;ui（现代设计） 关键技术 Canvas &#x2F; SVG 绘制思维导图 WebSocket 实时协作 拖拽 &amp; 节点连接 快捷键支持（Ctrl+Z 撤销，Ctrl+S 保存） Markdown &#x2F; JSON 格式存储导出 后端选型方案 框架 Node.js（轻量、适合前后端同构） 后端待定（高性能） Python（适合 AI 辅助功能） 实时协作 网络通信待定 待定：CRDT（冲突自由数据类型）支持多人编辑 AI 生成思维导图 待定：OpenAI &#x2F; ChatGPT 接口 自定义 NLP 解析文本生成结构化数据 数据库 待定：PostgreSQL（支持 JSON 数据存储） 待定：MongoDB（更适合文档存储） 待定：Redis（缓存 &amp; 协作数据同步） 待定：Firebase Firestore（Serverless 解决方案） 3. 部署方案 待定：Docker + Kubernetes（适合规模化应用） 待定：Serverless（Vercel &#x2F; Cloud Functions）（适合 MVP 快速上线） 待定：数据库托管（Supabase &#x2F; Firebase）（降低维护成本） 4. 关键功能✅ 图绘制✅ 实时协作✅ AI 生成✅ 跨平台支持（Web、桌面端 Electron、移动端 React Native）✅ 云端存储 &amp; 导出（JSON、Markdown、图片、PDF）✅ 权限管理 &amp; 共享 ison7 软件设计方案及设计描述文档 ison7 Level0 设计方案123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475flowchart TD subgraph 客户端层[客户端层] A1[Web 客户端 React Vite] A2[桌面客户端 Electron] A3[移动客户端 React Native] end subgraph 前端应用[前端应用] B1[前端 UI &amp; 交互] B2[WebSocket 通信模块] end subgraph API网关[API 网关] C[API 网关/反向代理] end subgraph 后端微服务[后端微服务] D1[用户与权限管理服务] D2[设计数据服务] D3[实时协作服务 CRDT, WebSocket] D4[AI 辅助服务 Python/OpenAI] D5[导出/打印服务] end subgraph 数据存储层[数据存储层] E1[(PostgreSQL / Firestore)] E2[(MongoDB)] E3[(Redis)] end subgraph 部署与运维[部署与运维] F1[Docker &amp; Kubernetes] F2[Serverless 部署 Vercel/Cloud Functions] end %% 连接客户端与前端应用 A1 --&gt; B1 A2 --&gt; B1 A3 --&gt; B1 %% 前端与 API 网关交互 B1 --&gt; C B2 --&gt; C %% API 网关转发请求到后端服务 C --&gt; D1 C --&gt; D2 C --&gt; D3 C --&gt; D4 C --&gt; D5 %% 后端服务与数据存储交互 D1 --&gt; E1 D2 --&gt; E1 D2 --&gt; E2 D3 --&gt; E3 %% 后端服务可调用 AI 第三方接口（如 OpenAI） D4 -. 调用 .-&gt; G&#123;&#123;OpenAI/ChatGPT&#125;&#125; %% 整个系统部署在运维平台 C --- F1 D1 --- F1 D2 --- F1 D3 --- F1 D4 --- F1 D5 --- F1 %% 或者采用 Serverless 部署方式 C --- F2 D1 --- F2 D2 --- F2 D3 --- F2 D4 --- F2 D5 --- F2 一、概述ison7 是一款基于 Web 的应用程序，旨在为用户提供类似 ComfyUI 的设计思维工具。该应用以 React Flow 的形式呈现，支持多种功能，如自定义节点、实时协作、AI 生成思维导图等。本设计方案将详细介绍软件的架构、技术选型、功能模块以及部署方案。 二、软件架构设计2.1 架构模式 前后端分离 ：前端和后端通过 API 进行交互，这种模式可以提升系统的扩展性和可维护性。前端专注于用户界面和交互逻辑，后端负责处理业务逻辑和数据存储。 微服务架构 ：将不同的功能拆分成独立的微服务，如存储服务、协作服务、AI 辅助服务等。微服务架构可以提高系统的灵活性和可扩展性，便于团队并行开发和维护。 Serverless ：采用 Serverless 架构可以降低成本，并且根据需求进行弹性扩展。Serverless 服务可以自动处理服务器的部署和管理，开发者只需关注业务逻辑。 2.2 技术栈选型2.2.1 前端 框架 ：采用 Vite + React + TypeScript + Canvas 的组合。 React 是一个流行的 JavaScript 库，用于构建用户界面，支持组件化开发，生态丰富，适合复杂交互。 TypeScript 可以提高代码的可维护性和可读性。 Vite 是一个快速的构建工具，能够提供更快的开发体验。 Canvas 用于绘制思维导图和节点连接。同时，考虑使用 react-flow 来实现节点的拖拽和连接功能。 UI 组件库 ：使用 Tailwind CSS 和 Shadcn&#x2F;ui 。 Tailwind CSS 是一个轻量级的 CSS 框架，支持自定义样式。 Shadcn&#x2F;ui 提供现代设计的 UI 组件。 2.2.2 后端 框架 ：选择 Node.js 作为后端框架，它轻量级且适合前后端同构开发。同时，考虑使用 Python 来实现 AI 辅助功能，因为 Python 在机器学习和自然语言处理领域有丰富的库和工具。 实时协作 ：网络通信方式待定，考虑使用 CRDT （冲突自由数据类型）来支持多人实时编辑，确保数据的一致性。 AI 生成思维导图 ：待定使用 OpenAI &#x2F; ChatGPT 接口，也可以开发自定义的 NLP 算法来解析文本并生成结构化数据。 2.2.3 数据库 PostgreSQL ：支持 JSON 数据存储，适合存储节点配置和用户数据。 MongoDB ：更适合文档存储，可用于存储思维导图的结构和历史记录。 Redis ：用于缓存和协作数据同步，提高系统的性能和响应速度。 Firebase Firestore ：作为 Serverless 解决方案，可降低数据库的维护成本。 2.3 部署方案 Docker + Kubernetes ：适合规模化应用的部署，能够实现自动化的容器编排和管理。 Serverless ：如 Vercel &#x2F; Cloud Functions ，适合 MVP 快速上线，降低开发和部署成本。 数据库托管 ：如 Supabase &#x2F; Firebase ，可以降低数据库的维护成本。 三、功能模块设计3.1 基于白板的设计思维 自定义节点 ：用户可以自定义各类节点，节点的样式使用框架显示，节点内容包括大模型配置选项和参数配置。 节点连接 ：节点与节点之间使用线连接，线条的显示支持动画效果。 3.2 快捷键支持支持常见的快捷键，如 Ctrl+Z 撤销操作， Ctrl+S 保存当前设计。 3.3 数据存储与导出支持多种格式的存储和导出，包括 Markdown 、 JSON 、 PDF 、 图片 、 SVG 、 HTML 等。 3.4 AI 生成思维导图通过调用 OpenAI &#x2F; ChatGPT 接口或自定义 NLP 算法，根据用户输入的文本生成思维导图。 3.5 实时协作支持多人实时协作编辑，使用 WebSocket 进行实时通信，确保数据的一致性。 3.6 跨平台支持支持在 Web、桌面端（使用 Electron）和移动端（使用 React Native）上运行。 3.7 其他功能 权限管理 ：对不同用户角色设置不同的操作权限。 国际化 ：支持多种语言，方便不同地区的用户使用。 主题切换 ：提供多种主题供用户选择。 自定义样式 ：用户可以自定义节点和界面的样式。 自定义快捷键 ：用户可以根据自己的习惯设置快捷键。 缩略图显示 ：提供思维导图的缩略图，方便用户快速浏览。 历史记录 ：记录用户的操作历史，支持回滚和查看。 分享 ：用户可以将思维导图分享给他人。 导入导出 ：支持从外部文件导入思维导图，也可以将当前设计导出到文件。 打印 ：支持打印当前思维导图。 付费界面 ：提供免费使用和月付费、年付费、终生使用的选项。 四、设计描述文档4.1 功能模块详细设计4.1.1 基于白板的设计思维 节点管理 ：用户可以通过鼠标点击或快捷键创建、删除和编辑节点。节点的样式和内容可以通过配置文件进行自定义。 节点连接 ：用户可以通过鼠标拖拽的方式连接两个节点，系统会自动绘制连接线，并支持动画效果。 4.1.2 快捷键支持 撤销操作 ：按下 Ctrl+Z 键，系统会撤销上一步操作。 保存操作 ：按下 Ctrl+S 键，系统会保存当前设计到本地或数据库。 4.1.3 数据存储与导出 存储 ：系统会将用户的设计数据以 JSON 格式存储到数据库中，方便后续的查询和恢复。 导出 ：用户可以选择将当前设计导出为 Markdown 、 PDF 、 图片 、 SVG 、 HTML 等格式。 4.1.4 AI 生成思维导图 用户输入 ：用户输入一段文本，系统会调用 OpenAI &#x2F; ChatGPT 接口或自定义 NLP 算法进行解析。 生成思维导图 ：根据解析结果，系统会自动生成思维导图，并显示在白板上。 4.1.5 实时协作 用户连接 ：多个用户可以通过 WebSocket 连接到同一个设计项目。 数据同步 ：当一个用户对思维导图进行修改时，系统会实时将修改同步到其他用户的界面上。 4.1.6 跨平台支持 Web 端 ：使用浏览器直接访问应用程序，无需安装额外的软件。 桌面端 ：使用 Electron 打包应用程序，支持在 Windows、Mac 和 Linux 系统上运行。 移动端 ：使用 React Native 开发移动应用，支持在 iOS 和 Android 系统上运行。 4.2 技术实现细节4.2.1 前端实现 组件化开发 ：使用 React 组件化开发，将不同的功能模块封装成独立的组件，提高代码的可维护性和复用性。 TypeScript 类型检查 ：使用 TypeScript 进行类型检查，确保代码的正确性和可维护性。 Canvas 绘制 ：使用 Canvas API 绘制思维导图和节点连接，实现动画效果。 WebSocket 通信 ：使用 WebSocket 实现实时协作功能，确保数据的实时同步。 4.2.2 后端实现 Node.js 服务 ：使用 Node.js 搭建后端服务，处理前端的请求和业务逻辑。 Python 脚本 ：使用 Python 脚本实现 AI 辅助功能，如 NLP 解析和思维导图生成。 数据库操作 ：使用相应的数据库驱动程序与数据库进行交互，实现数据的存储和查询。 4.2.3 数据库设计 PostgreSQL ：设计表结构，存储用户信息、节点配置和思维导图数据。 MongoDB ：存储思维导图的结构和历史记录，方便后续的查询和分析。 Redis ：使用 Redis 作为缓存和协作数据同步的工具，提高系统的性能和响应速度。 Firebase Firestore ：使用 Firebase Firestore 作为 Serverless 数据库，降低数据库的维护成本。 五、总结本设计方案详细介绍了 ison7 软件的架构、技术选型、功能模块以及部署方案。通过采用前后端分离、微服务架构和 Serverless 技术，提高了系统的扩展性和可维护性。同时，支持多种功能和跨平台使用，为用户提供了一个便捷的设计思维工具。"}]